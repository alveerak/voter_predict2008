{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train = np.genfromtxt('train_2008.csv', delimiter=',')\n",
    "X_train = train[1:, :-1]\n",
    "y_train = train[1:, -1]\n",
    "X_test = np.genfromtxt('test_2008.csv', delimiter=',')[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_err(y, real_y):\n",
    "    \"\"\"\n",
    "    This function returns the classification error between two equally-sized vectors of \n",
    "    labels; this is the fraction of samples for which the labels differ.\n",
    "    \n",
    "    Inputs:\n",
    "        y: (N, ) shaped array of predicted labels\n",
    "        real_y: (N, ) shaped array of true labels\n",
    "    Output:\n",
    "        Scalar classification error\n",
    "    \"\"\"\n",
    "    misclassified = 0\n",
    "    for i in range (len(y)):\n",
    "        if y[i] != real_y[i]:\n",
    "            misclassified += 1\n",
    "    return misclassified/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1  of  10  test indices: [   0    1    2 ... 6464 6465 6466]\n",
      "Fold  2  of  10  test indices: [ 6467  6468  6469 ... 12931 12932 12933]\n",
      "Fold  3  of  10  test indices: [12934 12935 12936 ... 19398 19399 19400]\n",
      "Fold  4  of  10  test indices: [19401 19402 19403 ... 25865 25866 25867]\n",
      "Fold  5  of  10  test indices: [25868 25869 25870 ... 32332 32333 32334]\n",
      "Fold  6  of  10  test indices: [32335 32336 32337 ... 38799 38800 38801]\n",
      "Fold  7  of  10  test indices: [38802 38803 38804 ... 45266 45267 45268]\n",
      "Fold  8  of  10  test indices: [45269 45270 45271 ... 51732 51733 51734]\n",
      "Fold  9  of  10  test indices: [51735 51736 51737 ... 58198 58199 58200]\n",
      "Fold  10  of  10  test indices: [58201 58202 58203 ... 64664 64665 64666]\n",
      "depth:  25\n",
      "min_leaf:  1\n",
      "test acc:  0.7787741433094072\n",
      "train acc:  0.9728300350999506\n",
      "Fold  1  of  10  test indices: [   0    1    2 ... 6464 6465 6466]\n",
      "Fold  2  of  10  test indices: [ 6467  6468  6469 ... 12931 12932 12933]\n",
      "Fold  3  of  10  test indices: [12934 12935 12936 ... 19398 19399 19400]\n",
      "Fold  4  of  10  test indices: [19401 19402 19403 ... 25865 25866 25867]\n",
      "Fold  5  of  10  test indices: [25868 25869 25870 ... 32332 32333 32334]\n",
      "Fold  6  of  10  test indices: [32335 32336 32337 ... 38799 38800 38801]\n",
      "Fold  7  of  10  test indices: [38802 38803 38804 ... 45266 45267 45268]\n",
      "Fold  8  of  10  test indices: [45269 45270 45271 ... 51732 51733 51734]\n",
      "Fold  9  of  10  test indices: [51735 51736 51737 ... 58198 58199 58200]\n",
      "Fold  10  of  10  test indices: [58201 58202 58203 ... 64664 64665 64666]\n",
      "depth:  30\n",
      "min_leaf:  1\n",
      "test acc:  0.7787277491651325\n",
      "train acc:  0.9937268347971255\n",
      "Fold  1  of  10  test indices: [   0    1    2 ... 6464 6465 6466]\n",
      "Fold  2  of  10  test indices: [ 6467  6468  6469 ... 12931 12932 12933]\n",
      "Fold  3  of  10  test indices: [12934 12935 12936 ... 19398 19399 19400]\n",
      "Fold  4  of  10  test indices: [19401 19402 19403 ... 25865 25866 25867]\n",
      "Fold  5  of  10  test indices: [25868 25869 25870 ... 32332 32333 32334]\n",
      "Fold  6  of  10  test indices: [32335 32336 32337 ... 38799 38800 38801]\n",
      "Fold  7  of  10  test indices: [38802 38803 38804 ... 45266 45267 45268]\n",
      "Fold  8  of  10  test indices: [45269 45270 45271 ... 51732 51733 51734]\n",
      "Fold  9  of  10  test indices: [51735 51736 51737 ... 58198 58199 58200]\n",
      "Fold  10  of  10  test indices: [58201 58202 58203 ... 64664 64665 64666]\n",
      "depth:  35\n",
      "min_leaf:  1\n",
      "test acc:  0.7790679641211602\n",
      "train acc:  0.9995876311391776\n",
      "Fold  1  of  10  test indices: [   0    1    2 ... 6464 6465 6466]\n",
      "Fold  2  of  10  test indices: [ 6467  6468  6469 ... 12931 12932 12933]\n",
      "Fold  3  of  10  test indices: [12934 12935 12936 ... 19398 19399 19400]\n",
      "Fold  4  of  10  test indices: [19401 19402 19403 ... 25865 25866 25867]\n",
      "Fold  5  of  10  test indices: [25868 25869 25870 ... 32332 32333 32334]\n",
      "Fold  6  of  10  test indices: [32335 32336 32337 ... 38799 38800 38801]\n",
      "Fold  7  of  10  test indices: [38802 38803 38804 ... 45266 45267 45268]\n",
      "Fold  8  of  10  test indices: [45269 45270 45271 ... 51732 51733 51734]\n",
      "Fold  9  of  10  test indices: [51735 51736 51737 ... 58198 58199 58200]\n",
      "Fold  10  of  10  test indices: [58201 58202 58203 ... 64664 64665 64666]\n",
      "depth:  40\n",
      "min_leaf:  1\n",
      "test acc:  0.7788515163065134\n",
      "train acc:  0.9999896907511715\n",
      "Fold  1  of  10  test indices: [   0    1    2 ... 6464 6465 6466]\n",
      "Fold  2  of  10  test indices: [ 6467  6468  6469 ... 12931 12932 12933]\n",
      "Fold  3  of  10  test indices: [12934 12935 12936 ... 19398 19399 19400]\n",
      "Fold  4  of  10  test indices: [19401 19402 19403 ... 25865 25866 25867]\n",
      "Fold  5  of  10  test indices: [25868 25869 25870 ... 32332 32333 32334]\n",
      "Fold  6  of  10  test indices: [32335 32336 32337 ... 38799 38800 38801]\n",
      "Fold  7  of  10  test indices: [38802 38803 38804 ... 45266 45267 45268]\n",
      "Fold  8  of  10  test indices: [45269 45270 45271 ... 51732 51733 51734]\n",
      "Fold  9  of  10  test indices: [51735 51736 51737 ... 58198 58199 58200]\n",
      "Fold  10  of  10  test indices: [58201 58202 58203 ... 64664 64665 64666]\n",
      "depth:  45\n",
      "min_leaf:  1\n",
      "test acc:  0.7788515330466685\n",
      "train acc:  1.0\n",
      "Fold  1  of  10  test indices: [   0    1    2 ... 6464 6465 6466]\n",
      "Fold  2  of  10  test indices: [ 6467  6468  6469 ... 12931 12932 12933]\n",
      "Fold  3  of  10  test indices: [12934 12935 12936 ... 19398 19399 19400]\n",
      "Fold  4  of  10  test indices: [19401 19402 19403 ... 25865 25866 25867]\n",
      "Fold  5  of  10  test indices: [25868 25869 25870 ... 32332 32333 32334]\n",
      "Fold  6  of  10  test indices: [32335 32336 32337 ... 38799 38800 38801]\n",
      "Fold  7  of  10  test indices: [38802 38803 38804 ... 45266 45267 45268]\n",
      "Fold  8  of  10  test indices: [45269 45270 45271 ... 51732 51733 51734]\n",
      "Fold  9  of  10  test indices: [51735 51736 51737 ... 58198 58199 58200]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds)\n",
    "\n",
    "\n",
    "for min_leaf in range (1, 25):\n",
    "    for depth in range (25, 60, 5):\n",
    "        # Iterate through cross-validation folds:\n",
    "        i = 1\n",
    "        train_acc = 0\n",
    "        test_acc = 0\n",
    "        for train_index, test_index in kf.split(X_train):\n",
    "\n",
    "            # Print out test indices:\n",
    "            print('Fold ', i, ' of ', num_folds, ' test indices:', test_index)\n",
    "\n",
    "            # Training and testing data points for this fold:\n",
    "            x_train_subset, x_test_subset = X_train[train_index], X_train[test_index]\n",
    "            y_train_subset, y_test_subset = y_train[train_index], y_train[test_index]\n",
    "\n",
    "\n",
    "\n",
    "            trees_subset = RandomForestClassifier(n_estimators=200, \n",
    "                                       max_depth=depth, \n",
    "                                       min_samples_leaf = min_leaf)\n",
    "            trees_subset.fit(x_train_subset, y_train_subset)\n",
    "            y_subset_predict = trees_subset.predict(x_test_subset)\n",
    "            y_train_subset_predict = trees_subset.predict(x_train_subset)\n",
    "            test_acc += (1 - classification_err(y_subset_predict, y_test_subset))\n",
    "            train_acc += (1- classification_err(y_train_subset_predict, y_train_subset))\n",
    "            i += 1\n",
    "        print (\"depth: \", depth)\n",
    "        print (\"min_leaf: \", min_leaf)\n",
    "        print (\"test acc: \", test_acc/num_folds)\n",
    "        print (\"train acc: \", train_acc/num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "trees = RandomForestClassifier(n_estimators=200, \n",
    "                               max_depth=40, \n",
    "                               min_samples_leaf = 1)\n",
    "trees.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=40, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "trees = RandomForestClassifier(n_estimators=200, \n",
    "                               max_depth=40, \n",
    "                               min_samples_leaf = 1)\n",
    "trees.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy:  0.9999690723243695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"model accuracy: \", trees.score(X_train, y_train))\n",
    "\n",
    "y_predict = trees.predict_proba(X_test)\n",
    "#print(y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "output.append([\"id\", \"target\"])\n",
    "for i in range(len(y_predict)):\n",
    "    #output.append([i, y_predict[i][0]])\n",
    "    output.append([i, y_predict[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'target'], [0, 0.505], [1, 0.185], [2, 0.175], [3, 0.405], [4, 0.245], [5, 0.08], [6, 0.255], [7, 0.615], [8, 0.02]]\n"
     ]
    }
   ],
   "source": [
    "print(output[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('voter_pred_2008.csv', mode='w') as voter_file:\n",
    "    voter_writer = csv.writer(voter_file, delimiter=\",\")\n",
    "    for i in output:\n",
    "        voter_writer.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dectree_max_depth(tree):\n",
    "    n_nodes = tree.node_count\n",
    "    children_left = tree.children_left\n",
    "    children_right = tree.children_right\n",
    "\n",
    "    def walk(node_id):\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            left_max = 1 + walk(children_left[node_id])\n",
    "            right_max = 1 + walk(children_right[node_id])\n",
    "            return max(left_max, right_max)\n",
    "        else: # leaf\n",
    "            return 1\n",
    "\n",
    "    root_node_id = 0\n",
    "    return walk(root_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59,\n",
       " 51,\n",
       " 50,\n",
       " 53,\n",
       " 51,\n",
       " 47,\n",
       " 43,\n",
       " 50,\n",
       " 50,\n",
       " 43,\n",
       " 49,\n",
       " 47,\n",
       " 47,\n",
       " 48,\n",
       " 48,\n",
       " 47,\n",
       " 57,\n",
       " 51,\n",
       " 54,\n",
       " 56,\n",
       " 51,\n",
       " 55,\n",
       " 56,\n",
       " 48,\n",
       " 49,\n",
       " 47,\n",
       " 51,\n",
       " 48,\n",
       " 51,\n",
       " 46,\n",
       " 51,\n",
       " 41,\n",
       " 43,\n",
       " 49,\n",
       " 46,\n",
       " 53,\n",
       " 52,\n",
       " 46,\n",
       " 59,\n",
       " 50,\n",
       " 53,\n",
       " 61,\n",
       " 46,\n",
       " 46,\n",
       " 48,\n",
       " 47,\n",
       " 53,\n",
       " 50,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 53,\n",
       " 49,\n",
       " 46,\n",
       " 54,\n",
       " 50,\n",
       " 49,\n",
       " 51,\n",
       " 54,\n",
       " 47,\n",
       " 58,\n",
       " 45,\n",
       " 47,\n",
       " 47,\n",
       " 49,\n",
       " 52,\n",
       " 64,\n",
       " 48,\n",
       " 45,\n",
       " 49,\n",
       " 54,\n",
       " 45,\n",
       " 50,\n",
       " 51,\n",
       " 49,\n",
       " 51,\n",
       " 58,\n",
       " 45,\n",
       " 46,\n",
       " 50,\n",
       " 44,\n",
       " 49,\n",
       " 53,\n",
       " 45,\n",
       " 53,\n",
       " 58,\n",
       " 47,\n",
       " 49,\n",
       " 54,\n",
       " 45,\n",
       " 46,\n",
       " 55,\n",
       " 51,\n",
       " 48,\n",
       " 54,\n",
       " 51,\n",
       " 45,\n",
       " 46,\n",
       " 50,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 55,\n",
       " 52,\n",
       " 56,\n",
       " 53,\n",
       " 53,\n",
       " 44,\n",
       " 49,\n",
       " 57,\n",
       " 49,\n",
       " 54,\n",
       " 50,\n",
       " 42,\n",
       " 49,\n",
       " 51,\n",
       " 53,\n",
       " 51,\n",
       " 51,\n",
       " 53,\n",
       " 52,\n",
       " 48,\n",
       " 52,\n",
       " 53,\n",
       " 53,\n",
       " 53,\n",
       " 48,\n",
       " 52,\n",
       " 52,\n",
       " 48,\n",
       " 52,\n",
       " 54,\n",
       " 50,\n",
       " 47,\n",
       " 48,\n",
       " 54,\n",
       " 45,\n",
       " 51,\n",
       " 44,\n",
       " 45,\n",
       " 55,\n",
       " 50,\n",
       " 43,\n",
       " 63,\n",
       " 52,\n",
       " 55,\n",
       " 46,\n",
       " 48,\n",
       " 49,\n",
       " 49,\n",
       " 48,\n",
       " 47,\n",
       " 49,\n",
       " 52,\n",
       " 45,\n",
       " 50,\n",
       " 47,\n",
       " 46,\n",
       " 49,\n",
       " 48,\n",
       " 49,\n",
       " 61,\n",
       " 54,\n",
       " 59,\n",
       " 50,\n",
       " 56,\n",
       " 44,\n",
       " 47,\n",
       " 48,\n",
       " 50,\n",
       " 49,\n",
       " 49,\n",
       " 55,\n",
       " 53,\n",
       " 54,\n",
       " 63,\n",
       " 55,\n",
       " 49,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 58,\n",
       " 53,\n",
       " 48,\n",
       " 55,\n",
       " 54,\n",
       " 59,\n",
       " 54,\n",
       " 50,\n",
       " 54,\n",
       " 47,\n",
       " 48,\n",
       " 51,\n",
       " 50,\n",
       " 52,\n",
       " 45,\n",
       " 44,\n",
       " 46,\n",
       " 54,\n",
       " 51]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dectree_max_depth(t.tree_) for t in trees.estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
